
# ğŸ“˜ Research Paper Analyzer  
**AIâ€‘Powered Tool for Automated Research Insight Extraction**

This project is an endâ€‘toâ€‘end implementation of an AIâ€‘driven research paper analysis system.  
It extracts text from PDF research papers, preprocesses the content, breaks it into manageable chunks, and uses an LLM (Google Gemini or any pluggable model) to generate structured academic summaries.

---

# ğŸš€ Key Features

### ğŸ” **PDF Processing**
- Upload any research paper in `.pdf` format.
- Extract text using **PyPDF2** (supports multiâ€‘page, multiâ€‘column text PDFs).
- Preprocess text to remove noise and prepare for summarization.

### ğŸ§  **AI Summarization**
- Uses Google Gemini (or other LLMs by swapping the client module).
- Produces structured JSON summaries with:
  - Title  
  - Domain  
  - Problem Statement  
  - Methods  
  - Results  
  - Strengths & Weaknesses  
  - Citations  
  - Keywords  

### ğŸ§© **Chunkâ€‘Based Processing**
- Handles papers that exceed LLM token limits.
- Splits extracted text into overlapping chunks.
- Summaries for each chunk are merged into a final comprehensive output.

### ğŸ–¥ï¸ **Streamlit Web App**
- Clean and interactive UI.
- Realâ€‘time progress indicators.
- Summary display and downloadable text output.
- Runs fully locally or in Docker.

### ğŸ›¡ï¸ **Security**
- `.env` for API keys  
- Gitâ€‘safe configuration  
- No user data stored  

### âš™ï¸ **Modular Architecture**
- Easy to swap AI providers (OpenAI, Gemini, Groq, etc.)
- Extendable for OCR, RAG, multiâ€‘PDF analysis.

---

# ğŸ“‚ Project Structure

```
research-paper-analyzer/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ app.py
â”œâ”€â”€ pdf_utils.py
â”œâ”€â”€ ai_client.py
â”œâ”€â”€ prompts.py
â”œâ”€â”€ ui_helpers.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .github/workflows/ci.yml
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pdf_utils.py
â”‚   â””â”€â”€ test_prompts.py
â””â”€â”€ scripts/
    â””â”€â”€ run_local.sh
```

---

# ğŸ› ï¸ Installation & Setup

## 1ï¸âƒ£ Clone the Project
```
git clone https://github.com/AirDhruv/research-paper-analyzer.git
cd research-paper-analyzer
```

## 2ï¸âƒ£ Create Virtual Environment
```
python -m venv .venv
source .venv/bin/activate       # Linux/Mac
.venv\Scripts\activate        # Windows
```

## 3ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```

## 4ï¸âƒ£ Configure API Keys
Copy `.env.example` â†’ `.env`
```
GOOGLE_API_KEY="your_api_key_here"
MAX_CHUNK_TOKENS=3000
CHUNK_OVERLAP=200
```

(You may substitute OpenAI keys if you modify `ai_client.py`.)

---

# â–¶ï¸ Running the Application

## Run Locally
```
streamlit run app.py
```

Then open the browser at:
```
http://localhost:8501
```

---

# ğŸ³ Docker Deployment

## Build Image
```
docker build -t rpa:latest .
```

## Run Container
```
docker run -p 8501:8501 --env-file .env rpa:latest
```

---

# ğŸ§ª Testing

```
pytest -q
```

Includes unit tests for:
- PDF text extraction
- Chunking logic
- Prompt formatting

---

# ğŸ§  Architecture Overview

## 1ï¸âƒ£ **Frontend (Streamlit)**
- File upload widget
- Progress bar during API processing
- Summary display area
- Download button for results

## 2ï¸âƒ£ **Backend Logic**
### `pdf_utils.py`
- Extracts all text from PDF (perâ€‘page extraction)
- Cleans and merges text
- Splits into wordâ€‘based chunks

### `ai_client.py`
- Provides a unified interface for LLMs
- Currently supports Google Gemini:
  - Initializes client
  - Sends prompt
  - Receives text completion

### `prompts.py`
- Stores structured prompt templates
- Ensures consistent summarization output

### `ui_helpers.py`
- Streamlit components for:
  - Result rendering
  - Download button

## 3ï¸âƒ£ **Chunking Strategy**
Chunking mitigates token limit problems:
- Splits text into windows of ~3000 words
- Adds 200â€‘word overlap to preserve context

Final summary = Gemini summary over merged chunk summaries.

---

# ğŸ“Š Performance

| Component | Average Time |
|----------|---------------|
| PDF extraction | 1â€“3 seconds |
| Chunk creation | Instant |
| Summarization (Gemini) | 15â€“90 seconds per chunk |
| Final merge summary | 10â€“30 seconds |

Performance depends on API latency + model speed.

---

# ğŸ§© Extending the System

## ğŸ”® Shortâ€‘Term Enhancements
- Add export as PDF, DOCX, MD
- Add keyword highlighting
- Add citations extraction using regex + LLM

## ğŸš€ Mediumâ€‘Term Enhancements
- Integrate OCR:
  - `pytesseract`
  - PDF-to-image conversion
- Add semantic search over uploaded PDFs
- Store summaries in a local database (SQLite/Postgres)

## ğŸŒ Longâ€‘Term Enhancements
- RAG pipeline (ChromaDB, Pinecone)
- Compare multiple research papers
- Topic clustering and visualization
- Fineâ€‘tune custom academic summarization model

---

# â“ FAQ

### **1. Does this support scanned PDFs?**  
Not by default â€” needs OCR. (Can be added.)

### **2. Does the app store my data?**  
No. Everything is processed in memory.

### **3. Can I use OpenAI instead of Gemini?**  
Yes â€” modify only `ai_client.py`.

### **4. Does it work offline?**  
No â€” requires LLM inference.

---

# ğŸ¤ Contributing

Pull requests are welcome!  
If adding new features, follow conventional commit styles and update tests.

---

# ğŸ“ License

MIT License.  
Feel free to use, modify, and distribute.

---

# ğŸ™Œ Acknowledgements

- Google Generative AI  
- PyPDF2  
- Streamlit Community  
- OpenAI Documentation  
- University Project Guidance  

---

If you want:
âœ… A downloadable ZIP  
âœ… A more detailed Deployment Guide  
âœ… A version using **OpenAI GPTâ€‘4.1**  
Just tell me!
